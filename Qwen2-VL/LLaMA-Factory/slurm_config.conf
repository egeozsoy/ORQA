#!/bin/sh

#SBATCH --job-name=orqa
#SBATCH --gres=gpu:1                   # Request 4 GPUs per node
#SBATCH --cpus-per-task=8              # CPUs per task
#SBATCH --time=0-160:00:00              # Runtime limit
#SBATCH --output=orqa.%j.out          # Output log
#SBATCH --error=orqa.%j.err           # Error log
#SBATCH --time=0-160:00:00  # Limit on the total run time (format: days-hours:minutes:seconds) -> NOT NEEDED ON BIG CLUSTERS
#SBATCH --mem=96G  # Memory in GB (Don't use more than 126G per GPU), maybe 128? -> NOT NEEDED ON BIG CLUSTERS

# activate corresponding environment
# conda deactivate # If you launch your script from a terminal where your environment is already loaded, conda won't activate the environment. This guards against that. Not necessary if you always run this script from a clean terminal
source ~/miniconda3/etc/profile.d/conda.sh
#conda activate ORQA
# FLASH ATTN NEEDS TO BE INSTALLED FROM THE SOURCE FOR CUDA 11.7 by previously setting CUDA HOME and LD_LIBRARY SOMETHING VARIABLES.
export GPUS_PER_NODE=1
export MASTER_ADDR=$(hostname)
export MASTER_PORT=29501

python -m src.train examples/train_qlora/qwen2vl_lora_sft_QA.yaml
#python -m src.train examples/train_qlora/qwen2vl_lora_sft_QA_temporality.yaml
#
#python -m src.train examples/train_qlora/qwen2vl_lora_pkd_QA_pkd.yaml
#python -m src.train examples/train_qlora/qwen2vl_lora_pkd_QA_pkd_depthreduce.yaml